{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc03343d",
   "metadata": {},
   "source": [
    "# [Module 1.1] 데이터 준비\n",
    "\n",
    "이 노트북은 주로 아래와 같은 작업을 합니다.\n",
    "- 훈련 데이터 세트 로딩\n",
    "- 데이터 샘플링하여 훈련, 테스트 데이터 세트 생성\n",
    "- 데이터 변형\n",
    "- 데이터 저장\n",
    "- 변수 저장\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e994c0",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업\n",
    "- 아래는 파이썬 캐키지를 임포트할때에 캐싱된 것을 사용하지 않고, 매번 리로딩 하는 세팅 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be77dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d3652",
   "metadata": {},
   "source": [
    "- 데이터 위치 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715da7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = '../../../data/AdTalking'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9418d",
   "metadata": {},
   "source": [
    "# 2. 훈련 데이터 로딩 및 데이터 정리\n",
    "- 아래는 데이터 로딩을 위해서 9.6 GB 가 필요합니다. 메모리 할당 에러가 나면 다른 노트북의 커널 세션을 삭제하고 해보세요. 그래도 안되면 메모리가 많은 노트북 인스턴스에서 다시 하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8678254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 10.4 s, total: 1min 38s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184903885</th>\n",
       "      <td>121312</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>340</td>\n",
       "      <td>2017-11-09 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184903886</th>\n",
       "      <td>46894</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>211</td>\n",
       "      <td>2017-11-09 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184903887</th>\n",
       "      <td>320126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>274</td>\n",
       "      <td>2017-11-09 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184903888</th>\n",
       "      <td>189286</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>259</td>\n",
       "      <td>2017-11-09 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184903889</th>\n",
       "      <td>106485</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>137</td>\n",
       "      <td>2017-11-09 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184903890 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ip  app  device  os  channel          click_time  \\\n",
       "0           83230    3       1  13      379 2017-11-06 14:32:21   \n",
       "1           17357    3       1  19      379 2017-11-06 14:33:34   \n",
       "2           35810    3       1  13      379 2017-11-06 14:34:12   \n",
       "3           45745   14       1  13      478 2017-11-06 14:34:52   \n",
       "4          161007    3       1  13      379 2017-11-06 14:35:08   \n",
       "...           ...  ...     ...  ..      ...                 ...   \n",
       "184903885  121312   12       1  10      340 2017-11-09 16:00:00   \n",
       "184903886   46894    3       1  19      211 2017-11-09 16:00:00   \n",
       "184903887  320126    1       1  13      274 2017-11-09 16:00:00   \n",
       "184903888  189286   12       1  37      259 2017-11-09 16:00:00   \n",
       "184903889  106485   11       1  19      137 2017-11-09 16:00:00   \n",
       "\n",
       "          attributed_time  is_attributed  \n",
       "0                     NaN              0  \n",
       "1                     NaN              0  \n",
       "2                     NaN              0  \n",
       "3                     NaN              0  \n",
       "4                     NaN              0  \n",
       "...                   ...            ...  \n",
       "184903885             NaN              0  \n",
       "184903886             NaN              0  \n",
       "184903887             NaN              0  \n",
       "184903888             NaN              0  \n",
       "184903889             NaN              0  \n",
       "\n",
       "[184903890 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file = 'train.csv'\n",
    "file_path = os.path.join(data_folder, file)\n",
    "\n",
    "df = pd.read_csv(file_path, parse_dates=['click_time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef72f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 184903890 entries, 0 to 184903889\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   ip               int64         \n",
      " 1   app              int64         \n",
      " 2   device           int64         \n",
      " 3   os               int64         \n",
      " 4   channel          int64         \n",
      " 5   click_time       datetime64[ns]\n",
      " 6   attributed_time  object        \n",
      " 7   is_attributed    int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(1)\n",
      "memory usage: 11.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165c1f3",
   "metadata": {},
   "source": [
    "## 불필요 컬럼 드랍\n",
    "- attributed_time 는 널 데이터가 많아서 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cb74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(raw_df, col):\n",
    "    df = raw_df.drop(columns=[col])\n",
    "    return df\n",
    "\n",
    "df = drop_column(df, col='attributed_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a50c58",
   "metadata": {},
   "source": [
    "## 컬럼 이름 변경\n",
    "- 아래의 레이블 및 click_time은 AFD 에서 지정한 컬럼 이름으로 변경 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26f46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'is_attributed':'EVENT_LABEL'})    \n",
    "df = df.rename(columns={'click_time':'EVENT_TIMESTAMP'})    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0845b98",
   "metadata": {},
   "source": [
    "# 3. 데이타 Resampling (훈련, 테스트)\n",
    "\n",
    "- 주어진 데이터의 시작 날짜와 끝 날짜를 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a244c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min time:  2017-11-06 14:32:21\n",
      "max time:  2017-11-09 16:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"min time: \", df.EVENT_TIMESTAMP.min())\n",
    "print(\"max time: \", df.EVENT_TIMESTAMP.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940af9c",
   "metadata": {},
   "source": [
    "## 훈련 및 테스트 샘플링 함수\n",
    "- 데이터 세트를 train_end 보다 작은 것을 훈련 데이터 세트, test_start 큰 것을 테스트 데이터 세트로 분리 합니다.\n",
    "- 전체 샘플링 개수를 기술 합니다. (에: total_samples = 200,000)\n",
    "- 샘플링 데이터 세트에서 훈련, 테스트 분리의 비율을 기술 합니다. \n",
    "    - (예: split_rate: 0.1)\n",
    "        - 훈련 90%, 테스트 10%\n",
    "- 결과로서 훈련, 테스트 샘플 데이터 세트에서 프로드의 비율 및 개수를 확인 합니다.        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c90f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample shape:  (180000, 7)\n",
      "train min time:  2017-11-06 15:08:24\n",
      "train max time:  2017-11-08 23:58:58\n",
      "Train fraud ratio:  0.00242\n",
      "# of Train frauds:  435\n",
      "\n",
      "test sample shape:  (20000, 7)\n",
      "test min time:  2017-11-09 00:00:01\n",
      "test max time:  2017-11-09 15:59:58\n",
      "Test fraud ratio:  0.00275\n",
      "# of test frauds:  55\n"
     ]
    }
   ],
   "source": [
    "def split_data_by_time(df, target_col, label_col, total_samples, split_rate, train_end, test_start, verbose=False):\n",
    "    '''\n",
    "    시간 관점으로 번반부튼 훈련, 후반부는 테스트 데이터로 해서 샘블링 함.\n",
    "    '''\n",
    "    \n",
    "    # 훈련 데이터 셋\n",
    "    train_df = df[df[target_col] <= train_end]   \n",
    "    train_num = int(total_samples * (1 - split_rate))    # 훈련 샘플 데이터 수\n",
    "    train_sample = train_df.sample(n = train_num, random_state=100)    # 샘플링    \n",
    "\n",
    "    print(\"train sample shape: \", train_sample.shape)\n",
    "    print(\"train min time: \", train_sample[target_col].min())\n",
    "    print(\"train max time: \", train_sample[target_col].max())\n",
    "    print(\"Train fraud ratio: \", round(train_sample[label_col].value_counts()[1] / train_sample.shape[0],5))\n",
    "    print(\"# of Train frauds: \", train_sample[label_col].value_counts()[1])     \n",
    "\n",
    "\n",
    "    # 테스트 데이터 셋    \n",
    "    test_df = df[df[target_col] >= test_start]    \n",
    "    test_num = int(total_samples * (split_rate))    # 테스트 샘플 데이터 수\n",
    "    test_sample = test_df.sample(n = test_num, random_state=100)    \n",
    "    \n",
    "\n",
    "    print(\"\\ntest sample shape: \", test_sample.shape)    \n",
    "    print(\"test min time: \", test_sample[target_col].min())\n",
    "    print(\"test max time: \", test_sample[target_col].max())\n",
    "    print(\"Test fraud ratio: \", round(test_sample[label_col].value_counts()[1] / test_sample.shape[0],5))    \n",
    "    print(\"# of test frauds: \", test_sample[label_col].value_counts()[1])         \n",
    "    \n",
    "    \n",
    "    return train_sample, test_sample\n",
    "    \n",
    "train_df, test_df = split_data_by_time(\n",
    "                       df=df, \n",
    "                       target_col='EVENT_TIMESTAMP', \n",
    "                       label_col = 'EVENT_LABEL',\n",
    "                       total_samples=200000, \n",
    "                       split_rate=0.1, \n",
    "                       train_end='2017-11-08 23:59', \n",
    "                       test_start='2017-11-09 00:00',    \n",
    "                       verbose = True,\n",
    "                  )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd6b43",
   "metadata": {},
   "source": [
    "# 4. 데이터 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26097ea",
   "metadata": {},
   "source": [
    "## 코드 데이터 (예: OS) 문자형 으로 변경\n",
    "- 숫자값에 'str' 를 넣어서 명시적으로 스트링으로 타입 변환\n",
    "이유는 csv로 데이터 프레임을 저장시에, string 타입이 일반 숫자형 타입으로 변경이 되어서 명시적으로 스트링으로 변경 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1083417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.p_utils import change_code_to_string\n",
    "\n",
    "train_df = change_code_to_string(train_df, col='ip', new_col='str_ip', verbose=False)\n",
    "train_df = change_code_to_string(train_df, col='app', new_col='str_app', verbose=False)\n",
    "train_df = change_code_to_string(train_df, col='device', new_col='str_device', verbose=False)\n",
    "train_df = change_code_to_string(train_df, col='os', new_col='str_os', verbose=False)\n",
    "train_df = change_code_to_string(train_df, col='channel', new_col='str_channel', verbose=False)\n",
    "\n",
    "test_df = change_code_to_string(test_df, col='ip', new_col='str_ip', verbose=False)\n",
    "test_df = change_code_to_string(test_df, col='app', new_col='str_app', verbose=False)\n",
    "test_df = change_code_to_string(test_df, col='device', new_col='str_device', verbose=False)\n",
    "test_df = change_code_to_string(test_df, col='os', new_col='str_os', verbose=False)\n",
    "test_df = change_code_to_string(test_df, col='channel', new_col='str_channel', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03716ff1",
   "metadata": {},
   "source": [
    "### 기존 컬럼 삭제\n",
    "- 위에서 같은 내용의 컬럼을 추가해서, 기존 컬럼은 삭제 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300c4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_column(train_df, col='ip')\n",
    "train_df = drop_column(train_df, col='app')\n",
    "train_df = drop_column(train_df, col='device')\n",
    "train_df = drop_column(train_df, col='os')\n",
    "train_df = drop_column(train_df, col='channel')\n",
    "\n",
    "test_df = drop_column(test_df, col='ip')\n",
    "test_df = drop_column(test_df, col='app')\n",
    "test_df = drop_column(test_df, col='device')\n",
    "test_df = drop_column(test_df, col='os')\n",
    "test_df = drop_column(test_df, col='channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92f627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 180000 entries, 37517593 to 62920975\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   str_ip           180000 non-null  object        \n",
      " 1   str_app          180000 non-null  object        \n",
      " 2   str_device       180000 non-null  object        \n",
      " 3   str_os           180000 non-null  object        \n",
      " 4   str_channel      180000 non-null  object        \n",
      " 5   EVENT_TIMESTAMP  180000 non-null  datetime64[ns]\n",
      " 6   EVENT_LABEL      180000 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cebc8e",
   "metadata": {},
   "source": [
    "# 5. 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb8b023",
   "metadata": {},
   "source": [
    "## 로컬에 데이터 CSV 로 저장\n",
    "- 로컬에 훈련 및 테스트 데이터 세트 저장\n",
    "    - data/train/train.csv\n",
    "    - data/test/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fb7ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/train-180000.csv is saved\n",
      "train_local_path:  data/train/train-180000.csv\n",
      "data/test/test-20000.csv is saved\n",
      "test_local_path:  data/test/test-20000.csv\n"
     ]
    }
   ],
   "source": [
    "from src.p_utils import save_csv_local\n",
    "\n",
    "train_file_name = 'train-' + str(train_df.shape[0]) + \".csv\"\n",
    "train_local_path = save_csv_local(raw_df=train_df, preproc_folder='data/train', \n",
    "                                  label='EVENT_LABEL', file_name=train_file_name)\n",
    "print(\"train_local_path: \", train_local_path)\n",
    "\n",
    "test_file_name = 'test-' + str(test_df.shape[0]) + \".csv\"\n",
    "test_local_path = save_csv_local(raw_df=test_df, preproc_folder='data/test', \n",
    "                                  label='EVENT_LABEL', file_name=test_file_name)\n",
    "print(\"test_local_path: \", test_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b05eb5",
   "metadata": {},
   "source": [
    "## S3에 데이로 업로딩\n",
    "- 위의 파일을 S3에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89716d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "# 프로젝트 변수\n",
    "project_prefix = 'adtalking_fraud_phase0'\n",
    "\n",
    "\n",
    "# S3에 저장되는 데이터의 기본 폴더 위치\n",
    "s3_train_data_uri = f\"s3://{bucket}/{project_prefix}/train\"\n",
    "s3_test_data_uri = f\"s3://{bucket}/{project_prefix}/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8edf2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_train_data_uri: \n",
      " s3://sagemaker-us-east-1-057716757052/adtalking_fraud_phase0/train/train-180000.csv\n",
      "s3_test_data_uri: \n",
      " s3://sagemaker-us-east-1-057716757052/adtalking_fraud_phase0/test/test-20000.csv\n"
     ]
    }
   ],
   "source": [
    "s3_train_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=train_local_path, \n",
    "    desired_s3_uri=s3_train_data_uri,    \n",
    ")\n",
    "print(\"s3_train_data_uri: \\n\", s3_train_data_uri)\n",
    "\n",
    "s3_test_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=test_local_path, \n",
    "    desired_s3_uri=s3_test_data_uri,    \n",
    ")\n",
    "print(\"s3_test_data_uri: \\n\", s3_test_data_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a729415",
   "metadata": {},
   "source": [
    "# 6. 변수 저장\n",
    "- 다른 노트북에서 아래 변수의 값을 사용하기 위해서 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b5be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_prefix' (str)\n",
      "Stored 'bucket' (str)\n",
      "Stored 'train_local_path' (str)\n",
      "Stored 'test_local_path' (str)\n",
      "Stored 's3_train_data_uri' (str)\n",
      "Stored 's3_test_data_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store project_prefix\n",
    "%store bucket\n",
    "%store train_local_path\n",
    "%store test_local_path\n",
    "%store s3_train_data_uri\n",
    "%store s3_test_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48dd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55ebad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc139f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
